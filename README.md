<!-- ![Herald Logo](https://github.com/Herald-Inc/herald-cli/blob/main/img/herald-logo.png) -->
<img style="max-width:500px" src="https://github.com/Herald-Inc/herald-cli/blob/main/img/herald-logo.png" alt="Herald Logo"  />

## Overview 
Herald is an observability solution that simplifies the deployment of the ELK stack, a popular set of tools used for monitoring the health and performance of software systems. It allows software developers to conveniently collect and explore telemetry data, including logs, traces, and metrics, through a single, user-friendly interface.

## Table of Contents 
- [Installation](#installation)
- [Herald Architectural Overview](#herald-architectural-overview)
  - [The Herald Pipeline](#the-herald-pipeline)
    - [Data Collection and Shipment](#data-collection-and-shipment)
      - [Filebeat](#filebeat)
      - [Elastic APM Agents](#elastic-apm-agents)
    - [Data Processing and Transformation](#data-processing-and-transformation)
      - [Logstash](#logstash-for-log-data-processing)
      - [APM Server](#apm-server-for-traces-and-metrics-processing)
    - [Data Storage](#data-storage)
      - [Elasticsearch](#elasticsearch)
    - [Data Querying and Visualization](#data-querying-and-visualization)
      - [Kibana](#kibana)
  - [Bastion Host](#bastion-host)

## Installation 
Herald can be installed using the Herald CLI. For more information about how to install and deploy Herald using the CLI, see [here](https://github.com/herald-app/herald-cli).

## Herald Architectural Overview 
Herald is built on the ELK stack-- Elasticsearch for data storage and indexing, Logstash for log processing, and Kibana for data querying and visualization.

Additionally, to enable the collection of traces and metrics, Herald deploys Fleet Server for Elastic Agent enrollment and management.

Finally, to enable data collection from the user's application, specific Elastic application utilities must be installed on the user's architecture: Filebeat for log collection, and APM Server for traces and metrics collection and processing.

### The Herald Pipeline 
The Herald pipeline comprises two separate data ingestion points, one for logs and another for traces and metrics, a data storage component, and a data visualization component. 

#### Data Collection and Shipment
##### Filebeat
Filebeat is a collection agent designed for collecting and shipping log data. Its primary function is to continuously scan for new log data and send such data to Logstash, where it is processed and transformed.

Filebeat is not part of the Herald deployment but is installed separately on the user’s application servers. After installation, it must be configured to monitor specific log files and output the data to Logstash.

##### Elastic APM Agents
For collecting and shipping traces and metrics data, we have Elastic APM Agents. APM agents are open-source libraries that collect data generated by an application. These agents are written in the same programming language (e.g. Golang, Python, or Node.js) as the application and can be easily installed like any other library.

Once installed, the user then instruments their code to allow the agents to collect tracing and metrics data. The APM agents then ship the data to the APM Server for processing.

#### Data Processing and Transformation
##### Logstash for Log Data Processing
Within the Herald pipeline, Logstash is configured to ingest data from Filebeat. The user must configure Logstash with an appropriate filter that enables a specific transformation of the ingested data to support a specific application use case. For example, a user may use the “geoip” filter to add information about the geographical location of IP addresses. Once the data is processed, it is sent to Elasticsearch for storage and indexing.

##### APM Server for Traces and Metrics Processing
The APM Server comprises two parts: the Elastic Agent and the APM Integration. Elastic Agents are installed on the user’s application servers to receive different data types, such as metrics and traces, from the APM Agents.

The Elastic Agent can be updated with configurations enabling the collection of new or different data sources. The configurations are implemented through agent policies. The APM Integration is one of those configurations that gets specified within an agent policy. The Elastic Agent with the APM Integration acts as the APM Server, which lives entirely on the user’s application server. The APM Server accepts tracing and metrics data from an APM Agent. The APM Server then processes the data, which includes validating it and transforming it into Elasticsearch documents before sending it on to Elasticsearch.

#### Data Storage 
##### Elasticsearch
Elasticsearch is a distributed search and analytics engine and document store. It stores complex data structures serialized as JSON documents. Elasticsearch stores and indexes data in a way that enables near real-time searching (i.e. within 1 second). It is a durable data store, which means it can persist long term data as needed. Within the Herald pipeline, Elasticsearch receives data from Logstash and the APM Server. It acts as a storage component that can be queried through Kibana to be visualized.

#### Data Querying and Visualization 
##### Kibana
Kibana is a powerful open-source data visualization and exploration platform. It provides a user-friendly interface for searching, analyzing, and visualizing large volumes of data in real-time. With Kibana, you can search, observe, and analyze your data, and visualize your findings in charts, gauges, maps, and graphs.

### Bastion Host 
To enable the ability to ssh into specific components of the Herald application, a Bastion Host is deployed as part of the Herald architecture. 
